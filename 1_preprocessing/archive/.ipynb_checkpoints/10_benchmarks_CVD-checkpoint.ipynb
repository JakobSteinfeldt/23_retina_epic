{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pathlib\n",
    "import datetime\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "node = !hostname\n",
    "if \"sc\" in node[0]:\n",
    "    base_path = \"/sc-projects/sc-proj-ukb-cvd\"\n",
    "else: \n",
    "    base_path = \"/data/analysis/ag-reils/ag-reils-shared/cardioRS\"\n",
    "print(base_path)\n",
    "\n",
    "project_label = \"22_retina_phewas\"\n",
    "project_path = f\"{base_path}/results/projects/{project_label}\"\n",
    "figure_path = f\"{project_path}/figures\"\n",
    "output_path = f\"{project_path}/data\"\n",
    "\n",
    "pathlib.Path(figure_path).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "experiment = '221108'\n",
    "experiment_path = f\"{output_path}/{experiment}\"\n",
    "pathlib.Path(experiment_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "USER = 'buergelt'\n",
    "BASE = pathlib.Path(f\"/home/{USER}/\")\n",
    "EXPERIMENT_NAME = '221109'\n",
    "#TEMPLATE_CONFIG = f\"{BASE}/config/\"  # template yaml to use\n",
    "TRAIN_SCRIPT = f\"{BASE}/projects/cardiors/code/22_retina_phewas_evaluation/1_processing/10_benchmarks_iteration_CVD.py\"\n",
    "#TRAIN_SCRIPT = f\"{BASE}/riskiano/riskiano/experiments/lukas/phewas/22_retina_phewas_notebooks/1_processing/08_coxph_fit_partition.py\"\n",
    "ACTIVATE_ENV_CMD = \"\"\"conda activate retrisk\"\"\"\n",
    "\n",
    "TAG = '221109'\n",
    "JOBNAME = 'benchmark'\n",
    "\n",
    "\n",
    "name_dict = {\n",
    "    \"predictions_cropratio0.66\": \"ConvNextSmall(Retina)+MLP_cropratio0.66\",\n",
    "}\n",
    "\n",
    "partitions = [i for i in range(22)]\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = '221109'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Benchmark jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(f\"/home/{USER}/tmp/{EXPERIMENT_NAME}/job_submissions\", exist_ok=True)\n",
    "os.makedirs(f\"/home/{USER}/tmp/{EXPERIMENT_NAME}/job_configs\", exist_ok=True)\n",
    "os.makedirs(f\"/home/{USER}/tmp/{EXPERIMENT_NAME}/job_outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f\"/home/{USER}/tmp/{EXPERIMENT_NAME}/job_outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_job_script(user, job_name, iteration, model, partition):\n",
    "\n",
    "    job_script_str = (\n",
    "        f\"\"\"#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name={job_name}  # Specify job name\n",
    "#SBATCH --ntasks 1 \n",
    "#SBATCH --cpus-per-task 16\n",
    "#SBATCH --mem=32G              # Specify number of nodes\n",
    "#SBATCH --time=2:30:00        # Set a limit on the total run time\n",
    "\n",
    "source ~/miniconda3/etc/profile.d/conda.sh\n",
    "{ACTIVATE_ENV_CMD}\n",
    "\n",
    "# ray start --head --num-cpus 16\n",
    "python {TRAIN_SCRIPT} --iteration {iteration} --model {model} --partition {partition}\"\"\"\n",
    "            )\n",
    "\n",
    "    return job_script_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit(path, job_name, job_script, time_stamp=None):\n",
    "    if not time_stamp:\n",
    "        time_stamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "    script_path_long = f\"{path}/{job_name}_{time_stamp}.sh\"\n",
    "\n",
    "    with open(script_path_long, \"w\") as outfile:\n",
    "        outfile.write(job_script)\n",
    "    script_path = f\"{path}/{job_name}.sh\"\n",
    "    try:\n",
    "        os.unlink(script_path)\n",
    "    except FileNotFoundError:  # because we cannot overwrite symlinks directly\n",
    "        pass\n",
    "    os.symlink(os.path.realpath(script_path_long), script_path)\n",
    "\n",
    "    output_path = f\"/home/{USER}/tmp/{EXPERIMENT_NAME}/job_outputs/{job_name}\"\n",
    "\n",
    "    print(job_script)\n",
    "    print(\"\\n\\nSubmission:\\n===========\\n\")\n",
    "    sub_cmd = (\n",
    "        f\"sbatch --error={output_path}_%j_stderr.out --output={output_path}_%j_stdout.out <\"\n",
    "        f\" {script_path}\"\n",
    "    )\n",
    "    print(sub_cmd)\n",
    "\n",
    "    ret = subprocess.run(sub_cmd, shell=True, cwd=os.getcwd(), capture_output=True)\n",
    "    print(ret.stdout.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HIER AENDERN:\n",
    "# Thore: range(0,10) + range(10,25)\n",
    "# Lukas: range(25,50)\n",
    "# Ben: range(50, 75)\n",
    "# Jakob: range(75, 100)\n",
    "\n",
    "iterations = [i for i in range(0,100)] #10,100, # 100,1000\n",
    "#iterations = [79, 82, 84, 86, 88, 92, 99]\n",
    "models = ['ImageTraining_[]_ConvNeXt_MLPHead_predictions_cropratio0.66', \n",
    "#               'ImageTraining_[]_ConvNeXt_MLPHead_predictions_cropratio0.5', \n",
    "#               'ImageTraining_[]_ConvNeXt_MLPHead_predictions_cropratio0.8'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "jobids = []\n",
    "for iteration in iterations:\n",
    "    for model in models:\n",
    "        for partition in partitions:\n",
    "            job_name = f\"{iteration}_{model}_{partition}_{JOBNAME}\"\n",
    "\n",
    "            job_script = make_job_script(user=USER, job_name=job_name, iteration=iteration, model=model, partition=partition) # partition currently not used in script\n",
    "\n",
    "            jobid = submit(\n",
    "                path=f\"/home/{USER}/tmp/{EXPERIMENT_NAME}/job_submissions\",\n",
    "                job_name=job_name,\n",
    "                job_script=job_script,\n",
    "            )\n",
    "\n",
    "            jobids.append(jobid)\n",
    "\n",
    "print(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = \"/sc-projects/sc-proj-ukb-cvd\"\n",
    "print(base_path)\n",
    "\n",
    "project_label = \"22_retina_phewas\"\n",
    "project_path = f\"{base_path}/results/projects/{project_label}\"\n",
    "figure_path = f\"{project_path}/figures\"\n",
    "output_path = f\"{project_path}/data\"\n",
    "\n",
    "experiment = '221108'\n",
    "experiment_path = f\"{output_path}/{experiment}\"\n",
    "experiment_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = '221109'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today()) if today is None else today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "benchmark_paths = list(Path(f\"{experiment_path}/benchmarks_cvd/{today}\").rglob('*.feather'))\n",
    "\n",
    "benchmarks_df = pd.concat([pd.read_feather(p) for p in benchmark_paths], axis=0)\n",
    "\n",
    "benchmarks_df.value_counts([\"iteration\"]).to_frame().sort_values(\"iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing = [i for i in range(0, 2) if i not in benchmarks_df[\"iteration\"].unique()]\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path(f\"{experiment_path}/benchmarks_cvd/{today}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmarks_df.reset_index(drop=True).to_feather(f\"{experiment_path}/benchmarks_cvd_cindex_{today}.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmarks_df.groupby([\"score\"]).mean(\"cindex\").sort_values(\"cindex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEANUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basedir = '/sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/221108/benchmarks_cvd/221109'\n",
    "for i in range(0, 1000):\n",
    "    filename = f'benchmark_cindex_{today}_model_ImageTraining_[]_ConvNeXt_MLPHead_predictions_cropratio0.66_iteration_{i}.feather'\n",
    "    try:\n",
    "        os.remove(os.path.join(basedir, filename))\n",
    "    except FileNotFoundError:\n",
    "        print(f'{i} not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = pd.read_feather('/sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/221108/prediction_paths_CVD.feather')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.query('endpoint==\"phecode_431-11\"').path.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = x.iloc[0, 4]\n",
    "file = f'/sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/221108/coxph_cvd/predictions/{path}'\n",
    "\n",
    "preds = pd.read_feather(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrisk",
   "language": "python",
   "name": "retrisk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
