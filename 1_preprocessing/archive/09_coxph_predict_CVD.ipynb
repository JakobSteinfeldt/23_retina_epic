{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "from lifelines.utils import CensoringType\n",
    "from lifelines.utils import concordance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "node = !hostname\n",
    "if \"sc\" in node[0]:\n",
    "    base_path = \"/sc-projects/sc-proj-ukb-cvd\"\n",
    "else: \n",
    "    base_path = \"/data/analysis/ag-reils/ag-reils-shared/cardioRS\"\n",
    "print(base_path)\n",
    "\n",
    "project_label = \"22_retina_phewas\"\n",
    "project_path = f\"{base_path}/results/projects/{project_label}\"\n",
    "figure_path = f\"{project_path}/figures\"\n",
    "output_path = f\"{project_path}/data\"\n",
    "\n",
    "pathlib.Path(figure_path).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "experiment = '221108'\n",
    "experiment_path = f\"{output_path}/{experiment}\"\n",
    "pathlib.Path(experiment_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "name_dict = {\n",
    "    \"predictions_cropratio0.66\": \"ConvNextSmall(Retina)+MLP_cropratio0.66\",\n",
    "}\n",
    "\n",
    "partitions = [i for i in range(22)]\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = '221109'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = f\"{experiment_path}/coxph_cvd/models_{today}\"\n",
    "model_list =  !ls $model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "endpoints = sorted([l.replace('_prevalent', '') for l in list(pd.read_csv('/sc-projects/sc-proj-ukb-cvd/results/projects/22_retinal_risk/data/220602/endpoints.csv').endpoint.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = [\"train\", \"valid\", 'test'] # \"test_left\", 'test_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extra_endpoints = set([\n",
    "    'phecode_059-1', #  \"Cerebral infarction [Ischemic stroke]\",\n",
    "    \"phecode_375-1\", # Glaucoma\n",
    "    \"phecode_374-42\", # Diabetic retinopathy\n",
    "    \"phecode_202\", # Diabetes mellitus\n",
    "    \"phecode_401\",\t#Hypertension\"  \n",
    "    \"phecode_103\", # Malignant neoplasm of the skin\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cardio_endpoints = set([\n",
    "    'phecode_431-11', #  \"Cerebral infarction [Ischemic stroke]\",\n",
    "    'phecode_404', #  \"Ischemic heart disease\",\n",
    "    'phecode_404-1', #  \"Myocardial infarction [Heart attack]\", # intervention\n",
    "    'phecode_424', #  \"Heart failure\", # intervention\n",
    "     'OMOP_4306655', #  \"All-Cause Death\", # intervention\n",
    "    'phecode_420' #  \"Cardiac arrest\", # intervention  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoints = set()\n",
    "endpoints.update(cardio_endpoints)\n",
    "endpoints.update(extra_endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_endpoints = [l.replace('_prevalent', '') for l in list(pd.read_csv('/sc-projects/sc-proj-ukb-cvd/results/projects/22_retinal_risk/data/220602/endpoints.csv').endpoint.values)]\n",
    "# endpoints = sorted(list(cardio_endpoints.intersection(all_endpoints)))\n",
    "endpoints = sorted(list(endpoints.intersection(all_endpoints)))\n",
    "endpoint_defs = pd.read_feather(f\"{output_path}/phecode_defs_220306.feather\").query(\"endpoint==@endpoints\").sort_values(\"endpoint\").set_index(\"endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today()) if today is None else today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eligable_eids = pd.read_feather(f\"{output_path}/eligable_eids_{today}.feather\")\n",
    "eids_dict = eligable_eids.set_index(\"endpoint\")[\"eid_list\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env MKL_NUM_THREADS=4\n",
    "%env NUMEXPR_NUM_THREADS=4\n",
    "%env OMP_NUM_THREADS=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()\n",
    "#ray start --head --port=6379 --num-cpus 64\n",
    "ray.init(address='auto')\n",
    "#ray.init(num_cpus=24)#, dashboard_port=24762, dashboard_host=\"0.0.0.0\", include_dashboard=True)#, webui_url=\"0.0.0.0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict COX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_path = pathlib.Path(f\"{experiment_path}/coxph/input\")\n",
    "model_path = f\"{experiment_path}/coxph_cvd/models_{today}\"\n",
    "\n",
    "out_path = f\"{experiment_path}/coxph_cvd/predictions_{today}\"\n",
    "pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [f.name for f in in_path.iterdir() if f.is_dir() and \"ipynb_checkpoints\" not in str(f)]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AgeSex = [\"age_at_recruitment_f21022_0_0\", \"sex_f31_0_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "from lifelines.exceptions import ConvergenceError\n",
    "import zstandard\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def get_score_defs():\n",
    "\n",
    "    with open(r'/sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/score_definitions.yaml') as file:\n",
    "        score_defs = yaml.full_load(file)\n",
    "    \n",
    "    return score_defs\n",
    "\n",
    "def get_features(endpoint, score_defs):\n",
    "    features = {\n",
    "        model: {\n",
    "            \"Age+Sex\": score_defs[\"AgeSex\"],\n",
    "            \"Retina\": [endpoint],\n",
    "            \"SCORE2\": score_defs[\"SCORE2\"],\n",
    "            \"ASCVD\": score_defs[\"ASCVD\"],\n",
    "            \"QRISK3\": score_defs[\"QRISK3\"],\n",
    "            \"Age+Sex+Retina\": score_defs[\"AgeSex\"] + [endpoint],\n",
    "            \"SCORE2+Retina\": score_defs[\"SCORE2\"] + [endpoint],\n",
    "            \"ASCVD+Retina\": score_defs[\"ASCVD\"] + [endpoint],\n",
    "            \"QRISK3+Retina\": score_defs[\"QRISK3\"] + [endpoint],\n",
    "            }\n",
    "        for model in models}\n",
    "    return features\n",
    "\n",
    "#def get_test_data(in_path, partition, models, mapping):\n",
    "def get_test_data(in_path, partition, models):\n",
    "    data = {model: pd.read_feather(f\"{in_path}/{model}/{partition}/test.feather\").set_index(\"eid\")#.replace(mapping)\n",
    "            for model in models}\n",
    "    return data\n",
    "    #left_data = {model: pd.read_feather(f\"{in_path}/{model}/{partition}/test_left.feather\").set_index(\"eid\").replace(mapping)for model in models}\n",
    "    #right_data = {model: pd.read_feather(f\"{in_path}/{model}/{partition}/test_right.feather\").set_index(\"eid\").replace(mapping)for model in models}\n",
    "    #return (left_data, right_data)\n",
    "            \n",
    "def load_pickle(fp):\n",
    "    with open(fp, \"rb\") as fh:\n",
    "        dctx = zstandard.ZstdDecompressor()\n",
    "        with dctx.stream_reader(fh) as decompressor:\n",
    "            data = pickle.loads(decompressor.read())\n",
    "    return data\n",
    "\n",
    "def predict_cox(cph, data_endpoint, endpoint, feature_set, partition, pred_path, model):\n",
    "    times = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "    time_cols = {t: f\"Ft_{t}\" for t in times}\n",
    "    \n",
    "    if feature_set==\"Age+Sex+MedicalHistory+I(Age*MH)\":\n",
    "        data_endpoint.columns = [c.replace(\"-\", \"\") for c in data_endpoint.columns]\n",
    "    \n",
    "    surv_test = 1-cph.predict_survival_function(data_endpoint, times=times)\n",
    "    temp_pred = data_endpoint.reset_index()[[\"eid\"]].assign(endpoint=endpoint, features=feature_set, partition=partition)\n",
    "    for t, col in time_cols.items(): \n",
    "        temp_pred[col] = surv_test.T[t].to_list()\n",
    "    \n",
    "    temp_pred.to_feather(f\"{out_path}/{endpoint}_{feature_set}_{model}_{partition}.feather\") \n",
    "\n",
    "# for both eyes\n",
    "def predict_cox_both_eyes(cph, data_endpoint_left, data_endpoint_right, endpoint, feature_set, partition, pred_path):\n",
    "    times = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "    time_cols = {t: f\"Ft_{t}\" for t in times}\n",
    "    \n",
    "    if feature_set==\"Age+Sex+MedicalHistory+I(Age*MH)\":\n",
    "        data_endpoint_left.columns = [c.replace(\"-\", \"\") for c in data_endpoint_left.columns]\n",
    "        data_endpoint_right.columns = [c.replace(\"-\", \"\") for c in data_endpoint_right.columns]\n",
    "\n",
    "    # left eye\n",
    "    surv_test_left = 1-cph.predict_survival_function(data_endpoint_left, times=times)\n",
    "    temp_pred_left = data_endpoint_left.reset_index()[[\"eid\"]].assign(endpoint=endpoint, features=feature_set, partition=partition)\n",
    "    for t, col in time_cols.items(): \n",
    "        temp_pred_left[col] = surv_test_left.T[t].to_list()\n",
    "    \n",
    "    temp_pred_left.to_feather(f\"{out_path}/{endpoint}_{feature_set}_{partition}_left.feather\")\n",
    "    \n",
    "    # right eye\n",
    "    surv_test_right = 1-cph.predict_survival_function(data_endpoint_right, times=times)\n",
    "    temp_pred_right = data_endpoint_right.reset_index()[[\"eid\"]].assign(endpoint=endpoint, features=feature_set, partition=partition)\n",
    "    for t, col in time_cols.items(): \n",
    "        temp_pred_right[col] = surv_test_right.T[t].to_list()\n",
    "    \n",
    "    temp_pred_right.to_feather(f\"{out_path}/{endpoint}_{feature_set}_{partition}_right.feather\")\n",
    "    \n",
    "    # mean both eyes\n",
    "    eids = list(surv_test_left.columns.values)\n",
    "    surv_test_mean = pd.concat((surv_test_left, surv_test_right), axis=1)\n",
    "    surv_test_mean.columns = [f'{col}_left' for col in list(surv_test_left.columns.values)] + [f'{col}_right' for col in list(surv_test_right.columns.values)]\n",
    "    for eid in eids:\n",
    "        eid_columns = [col for col in list(surv_test_mean.columns.values) if str(eid) in col]\n",
    "        surv_test_mean[f'{eid}_mean'] = surv_test_mean[eid_columns].mean(axis=1)\n",
    "    surv_test_mean = surv_test_mean[[col for col in list(surv_test_mean.columns.values) if 'mean' in col]].rename(columns={col: col.replace('_mean', '') for col in list(surv_test_mean.columns.values)})\n",
    "    \n",
    "    temp_pred_mean = data_endpoint_left.reset_index()[[\"eid\"]].assign(endpoint=endpoint, features=feature_set, partition=partition)\n",
    "    for t, col in time_cols.items(): \n",
    "        temp_pred_mean[col] = surv_test_mean.T[t].to_list()\n",
    "     \n",
    "    temp_pred_mean.to_feather(f\"{out_path}/{endpoint}_{feature_set}_{partition}_mean.feather\")\n",
    "\n",
    "@ray.remote\n",
    "def predict_endpoint(data_partition, eids_dict, endpoint, partition, models, features, model_path, out_path):\n",
    "    #data_partition_left, data_partition_right = data_partition\n",
    "    eids_incl = eids_dict[endpoint].tolist()\n",
    "    results = []\n",
    "    for model in models:\n",
    "        data_model = data_partition[model]\n",
    "        #data_model_left = data_partition_left[model]\n",
    "        #data_model_right = data_partition_right[model]\n",
    "        for feature_set, covariates in features[model].items():\n",
    "            identifier = f\"{endpoint}_{feature_set}_{model}_{partition}\"\n",
    "            pred_path = f\"{out_path}/{identifier}.feather\"\n",
    "            if not os.path.isfile(pred_path):\n",
    "                try:\n",
    "                    cph = load_pickle(f\"{model_path}/{identifier}.p\")\n",
    "                    data_endpoint = data_model[data_model.index.isin(eids_incl)]\n",
    "                    #data_endpoint_left = data_model_left[data_model_left.index.isin(eids_incl)]\n",
    "                    #data_endpoint_right = data_model_right[data_model_right.index.isin(eids_incl)]\n",
    "                    predict_cox(cph, data_endpoint, endpoint, feature_set, partition, pred_path, model)\n",
    "                    #predict_cox_both_eyes(cph, data_endpoint_left, data_endpoint_right, endpoint, feature_set, partition, pred_path)\n",
    "                except FileNotFoundErrorundError:\n",
    "                    print(f\"{identifier} not available\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### TEST ####\n",
    "\n",
    "mapping = {\"sex_f31_0_0\": {\"Female\":0, \"Male\":1}}\n",
    "\n",
    "for partition in tqdm([0]): # in tqdm(partitions) # TODO: CHANGE!\n",
    "    try:\n",
    "        data_partition_left, data_partition_right = get_test_data(in_path, partition, models, mapping)\n",
    "        for endpoint in tqdm(endpoints):\n",
    "            print('NEXT ENDPOINT:',endpoint)\n",
    "            features = get_features(endpoint)\n",
    "            if endpoint not in endpoints_not_overlapping_with_preds: # double check if this works as expected\n",
    "                predict_endpoint((data_partition_left, data_partition_right), eids_dict, endpoint, partition, models, features, model_path, out_path)\n",
    "            else:\n",
    "                print('Ã¼berspringe', endpoint)\n",
    "    except FileNotFoundError:\n",
    "        print('file not found')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "#mapping = {\"sex_f31_0_0\": {\"Female\":0, \"Male\":1}}\n",
    "score_defs = get_score_defs()\n",
    "\n",
    "ray_eids = ray.put(eids_dict)\n",
    "for partition in tqdm(partitions):\n",
    "    try:\n",
    "        del ray_partition\n",
    "    except:\n",
    "        print(\"Ray object not yet initialised\")\n",
    "    #ray_partition = ray.put(get_test_data(in_path, partition, models, mapping))\n",
    "    ray_partition = ray.put(get_test_data(in_path, partition, models))\n",
    "    progress = []\n",
    "    for endpoint in endpoints:\n",
    "        features = get_features(endpoint, score_defs)\n",
    "        progress.append(predict_endpoint.remote(ray_partition, ray_eids, endpoint, partition, models, features, model_path, out_path))\n",
    "    [ray.get(s) for s in tqdm(progress)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrisk",
   "language": "python",
   "name": "retrisk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
